# 图形验证码方案

## Introduction

## Design
### Part1 从视频截取图片并根据tag分类
- 视频源：哔哩哔哩
- 截取方式：随机截取

九张图片分为三类(来自三个不同tag) <br>
空间大小：(9\*8\*7/6) * (6\*5\*4/6) * (3\*2\*1/6) = 1680 <br>
十五张图片分为三类，其中九张用作验证 <br>
空间大小：15498(太难算了……质疑的话可以自己算一遍……不过即使不准误差也应该在100以内)

### Part2 根据用户验证情况反馈丰富数据集

![](src/数据流图.png)

## Jobs
- 从视频网站(bilibili)爬取视频和对应标签，依据标签建立文件夹，保存视频
- 从视频中随机截图按标签建立文件夹并保存(dataset1)
- 简单的网页界面，每次随机选择三个tag，每个tag从对应dataset1中选2个，对应dataset2中选3个
- 测试以及调整参数

### dataset文件夹目录结构
![](src/directoryTree.png)
1. source目录保存爬取的视频，按照tag保存至对应文件夹
2. dataset-test目录，保存直接从视频中截取的图片，按照tag保存至对应文件夹
3. dataset-valid目录，保存经验证合格的图片，按照tag保存对应文件夹

### 爬虫模块
1. 根据tag查视频(比如https://www.bilibili.com/tag/5265682)
    - 输入是tag的编号
    - 按时间循序查询，返回查询到的视频的av编号
2. 爬视频，靠这个玩意，[you-get](https://github.com/soimort/you-get)，这个东西真的好使……

### 截图模块
1. 对一个视频内的图片随机截图
2. 每个视频截取五张

### 网页界面
1. 随机选3个tag，从valid中的对应每个文件夹选三张图片，test中每个对应文件夹选两张图片。一共15张供用户分组。
2. 记录当用户验证通过时，来自test集的图片的分类正确率。
3. 将满足条件(2中提到的正确率到达threshold)的test集的图片移动至valid集。

### Others
#### 初始数据集
初始数据集，手动选择，~~用ILSVRC上效果最好的模型筛选第一批图片。~~(有待调研) <br>
结果：不可能了……效果最好的模型效果太变态了，我们只能避开物体识别类型的标签了。

#### 测试
- 直接使用截图，让用户做验证
- 是否有必要把tag显示给用户
- 使用Part2中提到的方案，筛选掉不合适的图片
- threshold选择多少才合适

## 测试记录
- 感觉没必要试了，直接加标签吧
- 不加标签慢慢的就关联歪了，而且收集成功情况下的数据难度太大

### 测试用户
关于参与实验的成员，都是我们小组的成员，更广泛的说，参与实验者是学生，虽然未做过实验，但根据我们的分析，我们的实验数据很可能会比真正应用到实际中的用户验证通过率高。<br>
不过我们的实验在不同测试间依然有可比性，因此该实验的数据仍具有参考价值。

### 测试数据
- 源数据集共有六个分组
- 每个视频截取五张图片
- 每个测试使用的图片和源视频都是独立不重复的

### 测试一
- 用户验证方式：随机对3×3的图片分组
- 测试次数：100
- 数据集：100+100

### 测试二
- 用户验证方式：随机对3×5的图片分组，来自valid集的九张分组成功即可完成验证
- 测试次数：100
- 数据集：100+100

### 测试三
- 用户验证方式：同二，不过valid集来自测试二中达标(因为这部分数据集数量略显不足，有额外手段添加部分)的图片
- 测试次数：100
- threshold：100%
- 数据集：100+100(此处20来自测试二)
- Note：测试二与三的用户必须更换

### 测试结果及分析
- 测试一：32/45
- 测试二：13/40
- 测试三：42/50

#### 测试一与二的对比
先简单分析一下测试一，首先根据实验者反馈，有大量难以判断如何分类的图片，但是有时通过排除，是能正确完成分组的。因为每组三个是固定的，这样最后不确定如何分组的图片最后放，是有很大概率分对的。<br>
对比测试二，虽然仍然是使用九张进行验证，但是加入了六张其实无实际作用的图片，每组的上限变为五个，导致的成功率下降极其明显。<br>
测试一里402/450=0.89,测试二里512/600=0.86，然而两者的验证成功率相差巨大，这可以看出验证空间大的效果。<br>
对那些用户未能成功分组的图片进行分析，发现几乎都是即使告知其正确分组，也无法理解的那种。这种图片，由于是随机截图，所以其产生难以控制，但我们希望有机制能把它们剔除掉。

#### 测试二与三的对比
这两组的对比是为了测试我们方案的可行性。其中测试二中的总分组正确率为512/600=0.86。其中测试三的更精确分析如下，对test集的分类正确率255/300=0.85，对valid集的分类正确率425/450=0.94。<br>
这些数据已经很能说明问题了，在valid集仅比test集正确率高0.1左右的情况下，验证成功率从32%左右提升到了82%左右。<br>
这次实验中的threshold选择了100%，因为数据集的不足和测试人员太少导致限制太多，最合适的threshold值实际并没有测试出来，这个值应该从希望的valid集正确率考虑，从我们实验推断，valid集上的正确率会与你选择的threshold值密切相关并比threshold值稍微低一点。

### 对机器的抵御能力
因为很多限制，这方面的实验没有实现，我们对这部分只有一些理论分析。首先因为图片是随机截取，我们是难以确定用户真正的分组依据的，比如有的地方是根据偶然截取的字幕完成的分组，有的则是根据对截取物体的联想(警车->警匪，砚台->书法)。对机器而言，这些未知的挑战是远比简单的物体识别任务难度要大的。<br>
另外当tag是物体时，当前的计算机视觉技术应该不比人类的识别能力差的，但tag是一些诸如"极限运动"的tag时，起码很难直接找到合适的模型。但tag的选择也需要小心，某些tag截取的图片很可能导致正确率飞速下降。

### 总结
最大成果就是证明了在配合我们方案的情况下，随机截图用来做验证码是有可能的。但是仍然有很多限制，比如一个正常视频中截取的图片如果缩放的太小，很多信息就看不清了。以及目前方案里，用户的一次验证其实是有点长的。